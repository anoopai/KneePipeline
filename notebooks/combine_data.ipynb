{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qdess_results(fem_dict):\n",
    "    \n",
    "    from re import M\n",
    "    import pandas as pd\n",
    "    # Initialize a dictionary to store aggregated results\n",
    "    aggregated_data = {}\n",
    "\n",
    "    # Map for side\n",
    "    side_map = {\n",
    "        'ant_fem': 'AN',\n",
    "        'med_wb': 'MC',\n",
    "        'lat_wb': 'LC',\n",
    "        'med_post': 'MP',\n",
    "        'lat_post': 'LP'\n",
    "    }\n",
    "\n",
    "    # Prepare a function to update the aggregated dictionary\n",
    "    def update_aggregated_data(data, layer, side, measurement, value):\n",
    "        key = (layer, side)\n",
    "        if key not in data:\n",
    "            data[key] = {\"T2Mean\": None, \"T2Median\": None, \"T2Std\": None, \"ThicknessMean\": None, \"ThicknessMedian\": None, \"ThicknessStd\": None}\n",
    "        data[key][measurement] = value\n",
    "\n",
    "    # Process the dictionary to fill the aggregated data dictionary\n",
    "    for key, value in fem_dict.items():\n",
    "        parts = key.split('_')\n",
    "        if len(parts) >= 5:\n",
    "            region = '_'.join(parts[:2])\n",
    "            measure_type = parts[-1]\n",
    "            \n",
    "            # Determine Layer\n",
    "            if 'deep' in key:\n",
    "                layer = 'Deep'\n",
    "            elif 'superficial' in key:\n",
    "                layer = 'Superficial'\n",
    "            else:\n",
    "                layer = 'Overall'\n",
    "\n",
    "            side = side_map.get(region, region)\n",
    "\n",
    "            # Determine if it's T2 or not\n",
    "            if measure_type == 'mean':\n",
    "                if 't2' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'T2 Mean', value)\n",
    "                elif 'mm' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'Thickness Mean', value)\n",
    "            elif measure_type == 'median':\n",
    "                if 't2' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'T2 Median', value)\n",
    "                elif 'mm' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'Thickness Median', value)\n",
    "            elif measure_type == 'std':\n",
    "                if 't2' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'T2 Std', value)\n",
    "                elif 'mm' in key:\n",
    "                    update_aggregated_data(aggregated_data, layer, side, 'Thickness Std', value)\n",
    "\n",
    "    # Convert the aggregated dictionary to a DataFrame\n",
    "    df = pd.DataFrame([\n",
    "        {\n",
    "            'Layer': layer,\n",
    "            'Sub-region': side,\n",
    "            'T2Mean': measurements['T2 Mean'],\n",
    "            'T2Median': measurements['T2 Median'],\n",
    "            'T2Std': measurements['T2 Std'],\n",
    "            'ThicknessMean': measurements.get('Thickness Mean'),\n",
    "            'ThicknessMedian': measurements.get('Thickness Median'),\n",
    "            'ThicknessStd': measurements.get('Thickness Std')\n",
    "        }\n",
    "        for (layer, side), measurements in aggregated_data.items()\n",
    "    ])\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['Layer', 'Sub-region', 'T2Mean', 'T2Median', 'T2Std', 'ThicknessMean', 'ThicknessMedian', 'ThicknessStd']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results not found: /dataNAS/people/anoopai/DESS_ACL_study/data/27-P/VISIT-5/aclr/results\n",
      "   Subject Visit  Knee        Layer Sub-region     T2Mean  T2Median  \\\n",
      "0     11-P     2  aclr      Overall         AN  28.504986      27.3   \n",
      "1     11-P     2  aclr      Overall         MC  27.556913      26.2   \n",
      "2     11-P     2  aclr      Overall         LC  30.330831      27.2   \n",
      "3     11-P     2  aclr      Overall         MP  30.431823      29.5   \n",
      "4     11-P     2  aclr      Overall         LP  29.978966      28.4   \n",
      "..     ...   ...   ...          ...        ...        ...       ...   \n",
      "10    35-C     5  ctrl  Superficial         LC  36.766469      35.6   \n",
      "11    35-C     5  ctrl         Deep         MP  24.628774      24.0   \n",
      "12    35-C     5  ctrl  Superficial         MP  31.199952      30.1   \n",
      "13    35-C     5  ctrl         Deep         LP  21.026027      20.6   \n",
      "14    35-C     5  ctrl  Superficial         LP  28.725357      27.2   \n",
      "\n",
      "        T2Std  ThicknessMean  ThicknessMedian  ThicknessStd  \n",
      "0   11.513834       1.898978         1.732932      0.729116  \n",
      "1   12.625785       1.528520         1.550969      0.432279  \n",
      "2   14.379130       1.559703         1.486113      0.566784  \n",
      "3   10.070854       1.647630         1.552442      0.428319  \n",
      "4   10.329713       1.668225         1.601736      0.512743  \n",
      "..        ...            ...              ...           ...  \n",
      "10  11.130434            NaN              NaN           NaN  \n",
      "11   6.953435            NaN              NaN           NaN  \n",
      "12  10.342668            NaN              NaN           NaN  \n",
      "13   5.506927            NaN              NaN           NaN  \n",
      "14   9.293226            NaN              NaN           NaN  \n",
      "\n",
      "[3243 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "dir_path= Path('/dataNAS/people/anoopai/DESS_ACL_study')\n",
    "data_path= dir_path / 'data/'\n",
    "nsm_results_path= dir_path/ 'results/Bscore_and_thickness'\n",
    "\n",
    "# List to keep track of the dictionaries\n",
    "analysis_complete = []\n",
    "\n",
    "qdess_df_all= pd.DataFrame()\n",
    "nsm_df_all= pd.DataFrame()\n",
    "\n",
    "# Find data folder and results folder\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for dir in dirs:\n",
    "        sub_dir_path= Path(root) / dir\n",
    "        if 'results' in sub_dir_path.name \\\n",
    "            and '42-C' not in str(sub_dir_path.parent) \\\n",
    "                and 'VISIT-6' not in str(sub_dir_path.parent) \\\n",
    "                    and ('27-P/VISIT-5/clat' not in str(sub_dir_path.parent)):   \n",
    "            main_dir_path = sub_dir_path.parent\n",
    "            results_path = Path(main_dir_path) / 'results'\n",
    "            qdess_results_file = Path(results_path) / 'qdess_results.json' \n",
    "            nsm_recon_file = Path(results_path) / 'NSM_recon_params.json'\n",
    "            \n",
    "            # print('Processing:', results_path)\n",
    "            # Split the path into components\n",
    "            sub_component = results_path.parts[6]  # '11-P'\n",
    "            visit_component = results_path.parts[7]  # 'VISIT-1'\n",
    "            knee_component = results_path.parts[8]  # 'clat'\n",
    "            \n",
    "            if os.path.exists(qdess_results_file):\n",
    "                # print('Processing:', results_path)\n",
    "            \n",
    "                with open(qdess_results_file) as f:\n",
    "                    qdess_results = json.load(f)\n",
    "                    \n",
    "                    # Filter dictionary to include only keys that contain 'fem'\n",
    "                    fem_dict = {key: value for key, value in qdess_results.items() if 'fem' in key}\n",
    "                    \n",
    "                    qdess_df= process_qdess_results(fem_dict)\n",
    "                    qdess_df['Subject']= sub_component\n",
    "                    qdess_df['Visit']= visit_component[-1]\n",
    "                    qdess_df['Knee']= knee_component\n",
    "                    \n",
    "                    cols= qdess_df.columns\n",
    "                    cols_list= cols.to_list()\n",
    "                    unique_cols = [col for col in cols_list if col not in ['Subject', 'Visit', 'Knee']]\n",
    "                    cols_order = ['Subject', 'Visit', 'Knee'] + unique_cols\n",
    "                    qdess_df= qdess_df[cols_order]\n",
    "                    \n",
    "                    qdess_df_all= pd.concat([qdess_df_all, qdess_df])\n",
    "                                    \n",
    "            else:\n",
    "                print('Results not found:', results_path)\n",
    "            \n",
    "# print('QDESS Results')\n",
    "print(qdess_df_all)\n",
    "\n",
    "qdess_df_all.to_excel(nsm_results_path / 'data_files/qdess_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject Visit  Knee    Bscore     scale  assd_bone_mm  assd_cartilage_mm\n",
      "0     11-P     2  aclr  1.213755  0.956195      0.242016           0.136475\n",
      "0     11-P     2  clat  1.768894  0.971741      0.283746           0.143941\n",
      "0     11-P     5  aclr  1.269275  0.961057      0.231375           0.146125\n",
      "0     11-P     5  clat  1.581905  0.965180      0.288937           0.131319\n",
      "0     11-P     1  aclr  1.286266  0.959444      0.233757           0.165380\n",
      "..     ...   ...   ...       ...       ...           ...                ...\n",
      "0     14-C     1  ctrl  0.752332  0.945463      0.229800           0.126727\n",
      "0     35-C     3  ctrl  0.977927  0.975928      0.231336           0.155260\n",
      "0     35-C     1  ctrl  1.023927  0.974444      0.242190           0.146634\n",
      "0     35-C     2  ctrl  1.032462  0.979290      0.221899           0.151532\n",
      "0     35-C     5  ctrl  1.002978  0.975705      0.257149           0.148585\n",
      "\n",
      "[224 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "dir_path= Path('/dataNAS/people/anoopai/DESS_ACL_study')\n",
    "data_path= dir_path / 'data/'\n",
    "nsm_results_path= dir_path/ 'results/Bscore_and_thickness'\n",
    "\n",
    "# List to keep track of the dictionaries\n",
    "analysis_complete = []\n",
    "\n",
    "qdess_df_all= pd.DataFrame()\n",
    "nsm_df_all= pd.DataFrame()\n",
    "\n",
    "# Find data folder and results folder\n",
    "for root, dirs, files in os.walk(data_path):\n",
    "    for dir in dirs:\n",
    "        sub_dir_path= Path(root) / dir\n",
    "        if 'results' in sub_dir_path.name \\\n",
    "            and '42-C' not in str(sub_dir_path.parent) \\\n",
    "                and 'VISIT-6' not in str(sub_dir_path.parent):  \n",
    "            main_dir_path = sub_dir_path.parent\n",
    "            results_path = Path(main_dir_path) / 'results'\n",
    "            qdess_results_file = Path(results_path) / 'qdess_results.json' \n",
    "            nsm_results_file = Path(results_path) / 'NSM_recon_params.json'\n",
    "            \n",
    "            \n",
    "            # print('Processing:', results_path)\n",
    "            # Split the path into components\n",
    "            sub_component = results_path.parts[6]  # '11-P'\n",
    "            visit_component = results_path.parts[7]  # 'VISIT-1'\n",
    "            knee_component = results_path.parts[8]  # 'clat'\n",
    "            \n",
    "            if os.path.exists(nsm_results_file):\n",
    "                \n",
    "                with open(nsm_results_file) as f:\n",
    "                    nsm_recon = json.load(f)\n",
    "    \n",
    "                # Collect the extracted information in a dictionary\n",
    "                nsm_results = {\n",
    "                    'Subject': sub_component,\n",
    "                    'Visit': visit_component[-1],\n",
    "                    'Knee': knee_component,\n",
    "                    'Bscore': nsm_recon['Bscore'],\n",
    "                    'scale': nsm_recon['scale'],\n",
    "                    'assd_bone_mm': nsm_recon['assd_bone_mm'],\n",
    "                    'assd_cartilage_mm': nsm_recon['assd_cartilage_mm'],\n",
    "                    \n",
    "                }\n",
    "                \n",
    "                nsm_df= pd.DataFrame(nsm_results, index=[0]).reset_index(drop=True)\n",
    "                nsm_df_all= pd.concat([nsm_df_all, nsm_df])\n",
    "                \n",
    "            else:\n",
    "                print('Results not found:', results_path)\n",
    "            \n",
    "# print('NSM Results')\n",
    "print(nsm_df_all)\n",
    "\n",
    "nsm_df_all.to_excel(nsm_results_path / 'data_files/nsm_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knee_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
