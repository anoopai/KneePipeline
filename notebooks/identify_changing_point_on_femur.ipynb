{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a80c520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from pyparsing import C\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from NSM.models import TriplanarDecoder\n",
    "from NSM.mesh import create_mesh\n",
    "from pymskt.mesh import get_icp_transform, cpd_register, non_rigidly_register\n",
    "from pymskt import mesh\n",
    "from vtk.util.numpy_support import numpy_to_vtk, vtk_to_numpy\n",
    "from pymskt.mesh.meshTools import smooth_scalars_from_second_mesh_onto_base, transfer_mesh_scalars_get_weighted_average_n_closest\n",
    "from pymskt.mesh import Mesh, BoneMesh, CartilageMesh\n",
    "from NSM.mesh.interpolate import interpolate_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ef53567",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= '/dataNAS/people/anoopai/DESS_ACL_study/results/BScore_and_FC_metrics/mean_shape_recon/change_overtime/BO/change_overtime_aclr/aclr_0.0.vtk'\n",
    "path2= '/dataNAS/people/anoopai/DESS_ACL_study/results/BScore_and_FC_metrics/mean_shape_recon/change_overtime/BO/change_overtime_aclr/aclr_3.0_interp.vtk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06731de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Diff\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "\n",
    "def compute_vertex_displacements(mesh1, mesh2, save_path=None):\n",
    "    \"\"\"\n",
    "    Compute x, y, z displacements and magnitude between corresponding points\n",
    "    in mesh1 and mesh2. Saves results on mesh2.\n",
    "    \"\"\"\n",
    "    # Ensure matching number of points\n",
    "    assert mesh1.n_points == mesh2.n_points, \"Meshes must have the same number of points\"\n",
    "\n",
    "    # Compute displacement vectors\n",
    "    disp_vectors = mesh2.points - mesh1.points  # shape (N, 3)\n",
    "    normx = disp_vectors[:, 0]\n",
    "    normy = disp_vectors[:, 1]\n",
    "    normz = disp_vectors[:, 2]\n",
    "    magnitude = np.linalg.norm(disp_vectors, axis=1)\n",
    "\n",
    "    # Attach as scalars to mesh2\n",
    "    mesh2.point_data['normx'] = normx\n",
    "    mesh2.point_data['normy'] = normy\n",
    "    mesh2.point_data['normz'] = normz\n",
    "    mesh2.point_data['magnitude'] = magnitude\n",
    "\n",
    "    return mesh2\n",
    "\n",
    "# Example usage\n",
    "mesh1 = pv.read(path1)\n",
    "mesh2 = pv.read(path2)\n",
    "out_path = path2\n",
    "\n",
    "diff_mesh = compute_vertex_displacements(mesh1, mesh2, save_path=out_path)\n",
    "diff_mesh =  BoneMesh(diff_mesh)\n",
    "diff_mesh.save_mesh(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dd2ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_latent_save_path = '/dataNAS/people/anoopai/DESS_ACL_study/results/BScore_and_FC_metrics/mean_shape_recon/BO_model/change_overtime/mean_latents.npz'\n",
    "latent= np.load(mean_latent_save_path)\n",
    "for key in latent.files:\n",
    "    print(f\"{key}: shape = {latent[key].shape}, dtype = {latent[key].dtype}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b42b1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x7228fa06dcd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import vtk\n",
    "from vtk.util.numpy_support import numpy_to_vtk\n",
    "\n",
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import vtk\n",
    "\n",
    "def compute_signed_distance(mesh1, mesh2):\n",
    "    \"\"\"\n",
    "    Compute signed distance from each point in mesh2 to the surface of mesh1.\n",
    "    Signed distance is Positive outside, negative inside, zero on surface.\n",
    "    Compute normal vector from mesh1 to mesh2.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure matching number of points\n",
    "    assert mesh1.n_points == mesh2.n_points, \"Meshes must have the same number of points\"\n",
    "    \n",
    "    # Build implicit distance function from surface of mesh1\n",
    "    implicit_distance = vtk.vtkImplicitPolyDataDistance()\n",
    "    surf = mesh1.extract_surface().triangulate().clean()\n",
    "    implicit_distance.SetInput(surf)  # For older VTK versions\n",
    "\n",
    "    # Evaluate signed distance at each point in mesh2\n",
    "    signed_distances = np.array([\n",
    "        implicit_distance.EvaluateFunction(point) for point in mesh2.points\n",
    "    ])\n",
    "\n",
    "    # Store result as point scalar\n",
    "    mesh2.point_data[\"signed_distance\"] = signed_distances\n",
    "    \n",
    "    # Compute displacement vectors\n",
    "    disp_vectors = mesh2.points - mesh1.points  # shape (N, 3)\n",
    "    normx = disp_vectors[:, 0]\n",
    "    normy = disp_vectors[:, 1]\n",
    "    normz = disp_vectors[:, 2]\n",
    "    magnitude = np.linalg.norm(disp_vectors, axis=1)\n",
    "\n",
    "    # Attach as scalars to mesh2\n",
    "    mesh2.point_data['normx'] = normx\n",
    "    mesh2.point_data['normy'] = normy\n",
    "    mesh2.point_data['normz'] = normz\n",
    "    \n",
    "    displacement_vectors = np.column_stack([\n",
    "    mesh2.point_data['normx'],\n",
    "    mesh2.point_data['normy'],\n",
    "    mesh2.point_data['normz']\n",
    "    ])\n",
    "    mesh2.point_data['displacement'] = displacement_vectors  # single vector field\n",
    "    \n",
    "    return mesh2\n",
    "\n",
    "# Example usage\n",
    "mesh1 = pv.read(path1)\n",
    "mesh2 = pv.read(path2)\n",
    "out_path = path2\n",
    "\n",
    "diff_mesh = compute_signed_distance(mesh1, mesh2)\n",
    "diff_mesh =  BoneMesh(diff_mesh)\n",
    "diff_mesh.save_mesh(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02b279dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Visit-1', 'Visit-2', 'Visit-3', 'Visit-4', 'Visit-5']\n",
      "Visit-1: shape = (1, 512), dtype = float64\n",
      "Visit-2: shape = (1, 512), dtype = float64\n",
      "Visit-3: shape = (1, 512), dtype = float64\n",
      "Visit-4: shape = (1, 512), dtype = float64\n",
      "Visit-5: shape = (1, 512), dtype = float64\n"
     ]
    }
   ],
   "source": [
    "mean_latent='/dataNAS/people/anoopai/DESS_ACL_study/results/BScore_and_FC_metrics/mean_shape_recon/change_overtime/BO/mean_latent_aclr.npz'\n",
    "\n",
    "latent_npz = np.load(mean_latent)  # mean_latent = path to .npz file\n",
    "print(latent_npz.files)  # Lists all keys stored in the npz file\n",
    "\n",
    "# Optionally, explore contents\n",
    "for key in latent_npz.files:\n",
    "    print(f\"{key}: shape = {latent_npz[key].shape}, dtype = {latent_npz[key].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c123ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "\n",
    "# Load meshes\n",
    "mesh1 = pv.read(path1)\n",
    "mesh5 = pv.read(path2)\n",
    "\n",
    "# Extract triangle indices (drop leading '3' from each face)\n",
    "faces1 = mesh1.faces.reshape(-1, 4)[:, 1:]\n",
    "faces5 = mesh5.faces.reshape(-1, 4)[:, 1:]\n",
    "\n",
    "# Check that all triangles are exactly the same\n",
    "same_faces = np.array_equal(faces1, faces5)\n",
    "print(\"Triangle correspondence check:\", same_faces)\n",
    "\n",
    "# Optional: print mismatches\n",
    "if not same_faces:\n",
    "    mismatch = np.where(~np.all(faces1 == faces5, axis=1))[0]\n",
    "    print(f\"Found {len(mismatch)} mismatched triangles. Example:\", faces1[mismatch[0]], \"vs\", faces5[mismatch[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeeb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compute_triangle_areas(mesh):\n",
    "    \"\"\"\n",
    "    Compute area of each triangle in a PyVista PolyData mesh.\n",
    "    Assumes each face is a triangle stored as [3, i, j, k].\n",
    "    \"\"\"\n",
    "    faces = mesh.faces.reshape(-1, 4)[:, 1:]  # Drop the leading '3' per triangle\n",
    "    points = mesh.points\n",
    "\n",
    "    v1 = points[faces[:, 1]] - points[faces[:, 0]]\n",
    "    v2 = points[faces[:, 2]] - points[faces[:, 0]]\n",
    "    cross_prod = np.cross(v1, v2)\n",
    "    areas = 0.5 * np.linalg.norm(cross_prod, axis=1)\n",
    "\n",
    "    return areas, faces\n",
    "\n",
    "def triangle_to_vertex_scalar(mesh, cell_values):\n",
    "    \"\"\"\n",
    "    Averages cell (triangle) values to point (vertex) values.\n",
    "    \"\"\"\n",
    "    n_points = mesh.points.shape[0]\n",
    "    point_values = np.zeros(n_points)\n",
    "    counts = np.zeros(n_points)\n",
    "\n",
    "    faces = mesh.faces.reshape(-1, 4)[:, 1:]\n",
    "\n",
    "    for i, tri in enumerate(faces):\n",
    "        for idx in tri:\n",
    "            point_values[idx] += cell_values[i]\n",
    "            counts[idx] += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    counts[counts == 0] = 1\n",
    "    return point_values / counts\n",
    "\n",
    "def triangle_area_change_heatmap(vtk_visit1_path, vtk_visit5_path_restruc, vtk_visit5_path, save_path=None, plot=True):\n",
    "    # Load meshes\n",
    "    mesh1 = pv.read(vtk_visit1_path)\n",
    "    mesh5 = pv.read(vtk_visit5_path_restruc)\n",
    "    mesh5_org= pv.read(vtk_visit5_path)\n",
    "\n",
    "    # Compute triangle areas\n",
    "    area1, _ = compute_triangle_areas(mesh1)\n",
    "    area5, _ = compute_triangle_areas(mesh5)\n",
    "    percent_change = 100 * (area5 - area1) / area1\n",
    "    percent_change = np.clip(percent_change, -50, 50)\n",
    "\n",
    "    # Convert to per-vertex scalar values\n",
    "    vertex_values = triangle_to_vertex_scalar(mesh5, percent_change)\n",
    "\n",
    "    # Assign as point scalars\n",
    "    mesh5.point_data['area_change (%)'] = vertex_values\n",
    "\n",
    "    # Save\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        mesh5.save(save_path)\n",
    "        print(f\"Saved mesh with vertex scalars to: {save_path}\")\n",
    "\n",
    "triangle_area_change_heatmap(path1, path2_restructured, path2, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knee_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
