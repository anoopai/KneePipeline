{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from math import log\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import vtk\n",
    "import shutil\n",
    "from pymskt.mesh import get_icp_transform, cpd_register, non_rigidly_register\n",
    "from pymskt import mesh\n",
    "from vtk.util.numpy_support import numpy_to_vtk, vtk_to_numpy\n",
    "from pymskt.mesh.meshTools import smooth_scalars_from_second_mesh_onto_base, transfer_mesh_scalars_get_weighted_average_n_closest\n",
    "from pymskt.mesh import Mesh, BoneMesh\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and configurations\n",
    "knee_to_use = ['aclr', 'clat', 'ctrl']\n",
    "dir_path = '/dataNAS/people/anoopai//DESS_ACL_study'\n",
    "code_dir_path = '/dataNAS/people/anoopai/KneePipeline/'\n",
    "data_path = os.path.join(dir_path, 'data')\n",
    "log_path = '/dataNAS/people/anoopai/KneePipeline/logs'\n",
    "output_file = os.path.join(log_path, f't2_and_thickness_change.txt')\n",
    "log_file_path = os.path.join(log_path, f'pipeline_DESS_errors.txt')\n",
    "mean_path = os.path.join(code_dir_path, 'mean_data')\n",
    "save_path = os.path.join(mean_path, f't2_and_thickness_change')\n",
    "mean_femur_path = os.path.join(mean_path, 'MeanFemur_mesh_B-only.vtk')\n",
    "\n",
    "parameter1= 'Diff_thickness (mm)'\n",
    "parameter2= 'Diff_T2_mean_filt'\n",
    "\n",
    "# parameter1= 'thickness (mm)'\n",
    "# parameter2= 'T2_mean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of the dictionaries\n",
    "analysis_complete = []\n",
    "data_all = []\n",
    "\n",
    "for subject in os.listdir(data_path):\n",
    "    subject_path = os.path.join(data_path, subject)\n",
    "\n",
    "    if os.path.isdir(subject_path):\n",
    "        # Iterate through each visit in the subject path\n",
    "        for visit in os.listdir(subject_path):\n",
    "            if visit not in ['VISIT-6', 'VISIT-1']:  # Exclude VISIT-6\n",
    "                visit_path = os.path.join(subject_path, visit)\n",
    "\n",
    "                if os.path.isdir(visit_path):\n",
    "                    # Iterate through each knee type in the visit path\n",
    "                    for knee in os.listdir(visit_path):\n",
    "                        knee_path = os.path.join(visit_path, knee)\n",
    "                        \n",
    "                        if os.path.isdir(knee_path) and knee in knee_to_use:\n",
    "                            path_image = os.path.join(knee_path, 'scans/qdess')\n",
    "                            path_save = os.path.join(knee_path, f'results_nsm')\n",
    "                            femur_path = os.path.join(path_save, 'femur_mesh_NSM_orig_reg2mean.vtk')\n",
    "                            \n",
    "                            sub_component= Path(knee_path).parts[6]  # '11-P'\n",
    "                            visit_component = Path(knee_path).parts[7]  # 'VISIT-1'\n",
    "                            knee_component = Path(knee_path).parts[8]  # 'clat'\n",
    "                            try:\n",
    "                            \n",
    "                                if os.path.exists(femur_path):\n",
    "                                    femur_mesh = BoneMesh(femur_path)\n",
    "                                    thickness_change_all = {}\n",
    "                                    t2_change_all = {}\n",
    "                                    scalar_names =[parameter1, parameter2]\n",
    "                                    data= {'sub': sub_component,\n",
    "                                            'visit': visit_component,\n",
    "                                            'knee': knee_component\n",
    "                                            }\n",
    "\n",
    "                                    for scalar_name in scalar_names:\n",
    "                                        data[scalar_name] = vtk_to_numpy(femur_mesh.GetPointData().GetArray(scalar_name))\n",
    "                                    \n",
    "                                    data_all.append(data)\n",
    "                                else:\n",
    "                                    print(f\"Femur mesh not found for {subject} {visit} {knee}\")\n",
    "                                    continue    \n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing {subject} {visit} {knee}: {e}\")\n",
    "                                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visits = ['VISIT-1', 'VISIT-2', 'VISIT-3', 'VISIT-4', 'VISIT-5']\n",
    "visits = ['VISIT-2', 'VISIT-3', 'VISIT-4', 'VISIT-5']\n",
    "knees = ['aclr', 'clat', 'ctrl']\n",
    "\n",
    "# Create a dictionary to store filtered results\n",
    "filtered_results = {knee: {visit: [] for visit in visits} for knee in knees}\n",
    "\n",
    "# Filter data\n",
    "for d in data_all:\n",
    "    knee_type = d['knee']\n",
    "    visit_type = d['visit']\n",
    "    if knee_type in knees and visit_type in visits:\n",
    "        filtered_results[knee_type][visit_type].append(d)\n",
    "\n",
    "# Access filtered results\n",
    "aclr_results = filtered_results['aclr']\n",
    "clat_results = filtered_results['clat']\n",
    "ctrl_results = filtered_results['ctrl']\n",
    "\n",
    "# Print results\n",
    "print(\"ACLR Results:\")\n",
    "print(aclr_results)\n",
    "print(\"\\nCLAT Results:\")\n",
    "print(clat_results)\n",
    "print(\"\\nCTRL Results:\")\n",
    "print(ctrl_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_v2= ctrl_results['VISIT-2']\n",
    "\n",
    "ctrl_v2_t2c = []\n",
    "for entry in ctrl_v2:\n",
    "    # print(entry)\n",
    "    row = (entry['Diff_T2_mean_filt'])\n",
    "    ctrl_v2_t2c.append(row)\n",
    "\n",
    "# Convert to numpy array\n",
    "ctrl_v2_t2c = np.array(ctrl_v2_t2c)\n",
    "ctrl_v2_t2c_fc_only = ctrl_v2_t2c[(ctrl_v2_t2c != 100) & (ctrl_v2_t2c != 200)]\n",
    "\n",
    "\n",
    "# # Save to npy file\n",
    "np.save('ctrl_v2_diffmaps.npy', ctrl_v2_t2c_fc_only)\n",
    "\n",
    "# ctrl_v2_t2c.flatten()\n",
    "plt.hist(ctrl_v2_t2c_fc_only.flatten(), bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity_threshold(difference_maps_all, std_values):\n",
    "    \n",
    "    '''\n",
    "    This function computes the intensity threshold for the T2-Cluster analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    difference_maps_all (array): A 4D NumPy array containing the 3D difference maps (axes 0-2) for all subjects (axis 3).\n",
    "    std_vales = A list of standard deviation values to calculate the intensity threshold at\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    # from utils.append_df_to_excel import append_df_to_excel\n",
    "\n",
    "    # Initialize an empty list to store the non-NaN values from all images\n",
    "    non_nan_values_all = np.array([])\n",
    "    \n",
    "    # Initialize an empty list to store the non-NaN values from all images\n",
    "    non_nan_values = []\n",
    "    \n",
    "    # Flatten the 3D array and remove NaN values\n",
    "    non_nan_values.extend(difference_maps_all[~np.isnan(difference_maps_all)])\n",
    "\n",
    "    # Convert the list of non-NaN values to a NumPy array\n",
    "    non_nan_values_all = np.array(non_nan_values)\n",
    "\n",
    "    mean_value = np.mean(non_nan_values)\n",
    "    std_dev = np.std(non_nan_values)\n",
    "    \n",
    "    intensity_threshold_data = pd.DataFrame({\n",
    "            'Mean': [mean_value],\n",
    "        })\n",
    "\n",
    "    # Calculate the value at x standard deviations\n",
    "    for std_value in std_values:\n",
    "        intensity_threshold = mean_value + std_value * std_dev\n",
    "        intensity_threshold_data[f'{std_value}*Std'] = mean_value + std_value * std_dev\n",
    "        \n",
    "    print(intensity_threshold_data)\n",
    "        \n",
    "    fig, ax= plt.subplots(figsize=(5, 5))\n",
    "    sns.histplot(non_nan_values_all,  \n",
    "                # kde=True,\n",
    "                bins='auto', \n",
    "                color = '#B8860B', \n",
    "                # hist_kws={'edgecolor':'#B8860B'},\n",
    "                # kde_kws={'linewidth': 1},\n",
    "                stat = 'density',\n",
    "                ax=ax,\n",
    "                )\n",
    "    ax.set_xlim(-20, 20)\n",
    "    \n",
    "    for std_value in std_values:\n",
    "\n",
    "        # Calculate the value at 2 standard deviations\n",
    "        stdev = mean_value + std_value * std_dev\n",
    "\n",
    "        # Draw a vertical line at 2 standard deviations above the mean\n",
    "        plt.axvline(x=stdev, color='#8B3E2F', linestyle='dashed', linewidth=1.5)\n",
    "        \n",
    "        # Annotate the lines with standard deviation values\n",
    "        plt.text(stdev, plt.ylim()[1] * 0.8, f'{std_value}SD= \\n \\n  {stdev:.2f}', fontsize=10, color='#000000')\n",
    "\n",
    "    plt.xlabel(f'T2 change (ms)', fontsize=10)\n",
    "    plt.ylabel('Probability Density', fontsize=10)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.title('T2-Cluster Intensity Threshold', fontsize=12)\n",
    "    plt.grid(True, alpha=0.5, linewidth=0.25)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your file\n",
    "cluster_map_all_path = 'ctrl_v2_diffmaps.npy'\n",
    "\n",
    "# Determine the file extension\n",
    "file_extension = os.path.splitext(cluster_map_all_path)[1]\n",
    "\n",
    "# Load the file based on the extension\n",
    "if file_extension in ['.pkl', '.pickle']:\n",
    "    with open(cluster_map_all_path, 'rb') as file:\n",
    "        cluster_map_all = pickle.load(file)\n",
    "elif file_extension == '.npy':\n",
    "    cluster_map_all = np.load(cluster_map_all_path)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "    \n",
    "# Compyte intensity threshold\n",
    "compute_intensity_threshold(\n",
    "    difference_maps_all = cluster_map_all,\n",
    "    std_values= [2]   # Specifiy all the values at which you want to compute the threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_path ='/dataNAS/people/anoopai/KneePipeline/data/10-P/VISIT-5/aclr/results_nsm/femur_mesh_NSM_orig_reg2mean.vtk'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label, find_objects\n",
    "\n",
    "vol_thresh_dict ={}\n",
    "mesh_path ='/dataNAS/people/anoopai/KneePipeline/data/10-P/VISIT-5/aclr/results_nsm/femur_mesh_NSM_orig_reg2mean.vtk'\n",
    "\n",
    "\n",
    "# Read the VTK file\n",
    "femur_mesh = BoneMesh(mesh_path)\n",
    "\n",
    "# Extract the Diff_T2_mean_int array\n",
    "diff_T2_mean_int = vtk_to_numpy(femur_mesh.GetPointData().GetArray('Diff_T2_mean_int'))\n",
    "\n",
    "# Specify the threshold sizes for connected components\n",
    "size_threshold = 2  # Example threshold, adjust as needed\n",
    "\n",
    "# Label the connected components (anything not -200)\n",
    "# Create a mask where values are not -200\n",
    "mask = diff_T2_mean_int != -200\n",
    "\n",
    "# Label the connected components\n",
    "labels, num_features = label(mask)\n",
    "\n",
    "# Measure the sizes of labeled regions\n",
    "sizes = np.bincount(labels.ravel())\n",
    "\n",
    "# Iterate over each component and set values to -200 if size is less than threshold\n",
    "for i in range(1, num_features + 1):\n",
    "    if sizes[i] < size_threshold:\n",
    "        diff_T2_mean_int [labels == i] = -200\n",
    "\n",
    "print(\"Filtered Array:\", diff_T2_mean_int )\n",
    "\n",
    "vol_thresh_dict = diff_T2_mean_int \n",
    "femur_mesh.point_data[f'Diff_T2_mean_vol'] = vol_thresh_dict \n",
    "\n",
    "femur_mesh.save_mesh(mesh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n",
      "WARNING: Mesh is now synonymous with pyvista.PolyData and thus this property is redundant and the Mesh object can be used for anything that pyvista.PolyData or vtk.vtkPolyData can be used for.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fileinput import filename\n",
    "import SimpleITK as sitk\n",
    "import pymskt as mskt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import warnings\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "from utils.filter_t2maps import *\n",
    "from utils.project_t2_data import *\n",
    "\n",
    "import pymskt.mesh.io as io\n",
    "from pymskt.image import read_nrrd\n",
    "from pymskt.mesh.meshTransform import SitkVtkTransformer\n",
    "from pymskt.mesh.meshTools import ProbeVtkImageDataAlongLine\n",
    "from pymskt.mesh.meshTools import get_surface_normals, n2l, l2n\n",
    "from pymskt.mesh.meshes import BoneMesh, CartilageMesh\n",
    "from pymskt.mesh.utils import is_hit, get_intersect, get_surface_normals, get_obb_surface\n",
    "\n",
    "path_save = '/dataNAS/people/anoopai/KneePipeline/data/7-P/VISIT-5/aclr/results_nsm'\n",
    "bone_name = 'femur'\n",
    "filename_save = 'qdess'\n",
    "\n",
    "femur_mesh_path = os.path.join(path_save, f'femur_mesh.vtk')\n",
    "fc_mesh_path  = os.path.join(path_save, f'femur_cart_0_mesh.vtk')\n",
    "sitk_seg_subregions_path  =  os.path.join(path_save, f'{filename_save}_subregions-labels.nrrd')\n",
    "sitk_seg_path = os.path.join(path_save, f'{filename_save}_all-labels.nrrd')\n",
    "\n",
    "# load meshes\n",
    "mesh_femur = BoneMesh(femur_mesh_path)\n",
    "mesh_fc = CartilageMesh(fc_mesh_path)\n",
    "sitk_seg_subregions = sitk.ReadImage(sitk_seg_subregions_path)\n",
    "sitk_seg = sitk.ReadImage(sitk_seg_path)\n",
    "\n",
    "# Assign mesh objects\n",
    "mesh_femur.seg_image = sitk_seg_subregions\n",
    "cart_labels = [11, 12, 13, 14, 15]\n",
    "mesh_femur.list_cartilage_labels=cart_labels\n",
    "mesh_femur.seg_image = sitk_seg\n",
    "mesh_femur.list_cartilage_meshes = [mesh_fc]\n",
    "\n",
    "# get the T2 map   \n",
    "map_path_nrrd= os.path.join(path_save, f'{filename_save}_t2map.nrrd')\n",
    "map_path_filt_nrrd= os.path.join(path_save, f'{filename_save}_t2map_filt.nrrd')\n",
    "\n",
    "# filter the T2 map\n",
    "_ = filter_t2maps(t2_map_path=map_path_nrrd, fwhm= 1, t2_map_save_path=map_path_filt_nrrd)\n",
    "\n",
    "# project the T2 data onto the femur mesh\n",
    "data_probe_t2= project_T2_data(mesh_femur, mesh_fc, map_path_nrrd)\n",
    "mesh_femur.set_scalar('T2_max', data_probe_t2.max_data)\n",
    "mesh_femur.set_scalar('T2_mean', data_probe_t2.mean_data)\n",
    "mesh_femur.set_scalar('T2_std', data_probe_t2.std_data)\n",
    "\n",
    "data_probe_t2_filt= project_T2_data(mesh_femur, mesh_fc, map_path_filt_nrrd)\n",
    "mesh_femur.set_scalar('T2_max_filt', data_probe_t2_filt.max_data)\n",
    "mesh_femur.set_scalar('T2_mean_filt', data_probe_t2_filt.mean_data)\n",
    "mesh_femur.set_scalar('T2_std_filt', data_probe_t2_filt.std_data)\n",
    "\n",
    "save_path = os.path.join(path_save, f'femur_mesh.vtk')\n",
    "mesh_femur.save_mesh(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 12.53626974, 13.14231949, ..., 36.18296175,\n",
       "       36.51046449, 38.04290891])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_probe_t2_filt.mean_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knee_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
